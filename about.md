---
title: About
layout: page
---
<!-- ![Profile Image]({{ site.url }}/{{ site.picture }}) -->

<p>I am a research scientist at the Johns Hopkins affiliated <a href="https://hltcoe.jhu.edu/">Human Language Technology Center of Excellence</a> (HLTCOE). I am broadly interested in speech technologies, but I
have primarily worked on multilingual and cross-lingual acoustic modeling for
low-resource language ASR and topic identification. Recently, I have been increasingly interested in Machine Translation.
I finished my PhD at Johns Hopkins University in 2021 advised by
<a href="https://www.clsp.jhu.edu/faculty/sanjeev-khudanpur">Sanjeev Khudanpur</a>.
I have worked on end-to-end speech recognition ESPnet and Fairseq and I am an occasional
contributer to Kaldi. Before starting at Johns Hopkins I used to
work on machine learning applications in atmospheric science. Outside of work,
I spend most of my time making music and with my family.</p> 

<hr>

<h2>Publications</h2>

<p><a href="https://arxiv.org/pdf/2211.01458.pdf">Towards Zero-Shot Code-Switched Speech Recognition</a><br />
<em style="font-size: 75%">Brian Yan, <strong>Matthew Wiesner</strong>, Ondřej Kleich, Preethi Jyothi, Shinji Watanabe, Accepted at ICASSP 2023</em></p>

<p>Building Keyword Search Systems from End-To-End ASR Systems<br />
<em style="font-size: 75%">Ruizhe Huang, <strong>Matthew Wiesner</strong>, Leibny Paola García-Perera, Dan Povey, Jan Trmal, Sanjeev Khudanpur, Accepted at ICASSP 2023</em></p>

<p><a href="https://aclanthology.org/2022.iwslt-1.29.pdf">JHU IWSLT 2022 Dialect Speech Translation System Description</a><br />
<em style="font-size: 75%">Jinyi Yang, Amir Hussein, <strong>Matthew Wiesner</strong>, Sanjeev Khudanpur, IWSLT 2022</em></p>

<p><a href="https://arxiv.org/pdf/2110.04863.pdf">Injecting Text and Cross-Lingual Supervision in Few-shot Learning from Self-supervised Models</a><br />
<em style="font-size: 75%"><strong>Matthew Wiesner</strong>, Desh Raj, Sanjeev Khudanpur, ICASSP 2022</em></p>

<p><a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/wiesner21_interspeech.pdf">Training Hybrid Models on Noisy Transliterated Transcripts for
  Code-Switched Speech Recognition</a><br />
<em style="font-size: 75%"><strong>Matthew Wiesner</strong>, Mousmita Sarma, Ashish Arora, Desh Raj, Dongji Gao, Ruizhe Huang,
Supreet Preet, Moris Johnson, Zikra Iqbal, Nagendra Goel, Jan Trmal, Paola García, Sanjeev Khudanpur, Interspeech 2021</em></p>

<p><a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/salesky21_interspeech.pdf">The Multilingual TEDx Corpus for Speech Recognition and Translation</a><br />
<em style="font-size: 75%">Elizabeth Salesky, <strong>Matthew Wiesner</strong>, Jacob Bremerman, Roldano Cattoni, Matteo Negri, Marco Turchi, Douglas W. Oard, Matt Post, Interspeech 2021</em></p>
  
<p><a href="https://arxiv.org/pdf/2005.13962.pdf">A Corpus for Large-Scale Phonetic Typology</a><br />
<em style="font-size: 75%">Elizabeth Salesky, Eleanor Chodroff, Tiago Pimentel, <strong>Matthew Wiesner</strong>, Ryan Cotterell, Alan W Black, Jason Eisner, ACL 2020</em></p>

<p><a href="https://ieeexplore.ieee.org/abstract/document/9004019">Zero-Shot Pronunciation Lexicons for Cross-Language Acoustic Model Transfer Settings</a><br />
<em style="font-size: 75%"><strong>Matthew Wiesner</strong>, Oliver Adams, David Yarowsky, Jan Trmal Sanjeev Khudanpur, ASRU 2019</em></p>

<p><a href="https://arxiv.org/abs/1812.03919">Pretraining by Backtranslation for End-to-end ASR in Low-Resource Settings</a><br />
<em style="font-size: 75%"><strong>Matthew Wiesner</strong>, Adithya Renduchintala, Shinji Watanabe, Chunxi Liu, Najim Dehak, Sanjeev Khudanpur, INTERSPEECH 2019</em></p>

<p><a href="https://arxiv.org/abs/1811.03451">Analysis of Multilingual Sequence-to-Sequence speech recognition systems</a><br />
<em style="font-size: 75%">Martin Karafiát, Murali Karthick Baskar, Shinji Watanabe, Takaaki Hori, <strong>Matthew Wiesner</strong>, Jan "Honza'' Černocký, INTERSPEECH 2019</em></p>

<p><a href="https://www.aclweb.org/anthology/N19-1009">Massively Multilingual Adversarial Speech Recognition</a><br />
<em style="font-size: 75%">Oliver Adams, <strong>Matthew Wiesner</strong>, Shinji Watanabe, David Yarowsky, NAACL 2018</em></p>

<p><a href="https://arxiv.org/abs/1810.03459">Multilingual sequence-to-sequence speech recognition:architecture, transfer learning, and language modeling</a><br />
<em style="font-size: 75%">Jaejin Cho, Murali Karthick Baskar, Ruizhi Li, <strong>Matthew Wiesner</strong>, Sri Harish Mallidi, Nelson Yalta,Martin Karafiat, Shinji Watanabe, Takaaki Hori, SLT 2018</em></p>

<p><a href="https://arxiv.org/pdf/1807.06204.pdf">Low-Resource Centextual Topic Identification on Speech</a><br />
<em style="font-size: 75%">Chunxi Liu, <strong>Matthew Wiesner</strong>, Shinji Watanabe, Craig Harman, Jan Trmal, Najim Dehak, Sanjeev Khudanpur, SLT 2018.</em></p>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1836.pdf">Automatic Speech Recognition and Topic Identification for Almost-Zero-Resource Languages</a><br />
<em style="font-size: 75%"><strong>Matthew Wiesner</strong>, Chunxi Liu, Lucas Ondel, Craig Harman, Vimal Manohar, Jan Trmal, Zhongqiang Huang, Najim Dehak, Sanjeev Khudanpur, INTERSPEECH 2018.</em></p>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2018/abstracts/2456.html">Multi-Modal Data Augmentation for End-to-end ASR</a>
<a href="https://www.clsp.jhu.edu/2018/09/06/clsp-students-win-best-student-paper-award-at-interspeech-2018/"><em style="font-size: 75%"><small><span style="color:red">Best Student Paper!</span></small></em></a><br />
<em style="font-size: 75%">Adithya Renduchintala, Shuoyang Ding, <strong>Matthew Wiesner</strong> and Shinji Watanabe, INTERSPEECH 2018.</em></p>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2018/abstracts/1456.html">ESPnet: End-to-End Speech Processing Toolkit</a><br />
<em style="font-size: 75%">Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, <strong>Matthew Wiesner</strong>, Nanxin Chen, Adithya Renduchintala, Tsubasa Ochiai, INTERSPEECH 2018.</em></p>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/1093.PDF">Topic Identification for Speech without ASR</a> <em style="font-size: 75%"><small><span style="color:red">Nominated for Best Student Paper</span></small></em><br />
<em style="font-size: 75%">Chunxi Liu, Jan Trmal, <strong>Matthew Wiesner</strong>, Craig Harman, Sanjeev Khudanpur, INTERSPEECH 2017.</em></p>

<p><a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0601.PDF">The Kaldi OpenKWS System: Improving Low Resource Keyword Search</a><br />
<em style="font-size: 75%">Jan Trmal, <strong>Matthew Wiesner</strong>, Vijayaditya Peddinti, Xiaohui Zhang, Pegah Ghahremani, Yiming Wang, Vimal Manohar, Hainan Xi, Daniel Povey, Sanjeev Khudanpur, INTERSPEECH 2017.</em></p>

<p><a href="https://ams.confex.com/ams/94Annual/webprogram/Paper242901.html">Automated Detection of Radar Severe Weather Signatures</a><br />
<em style="font-size: 75%"><strong>Matthew Wiesner</strong>, Joseph Hardin, V. Chandrasekaran, American Meteorological Society 2014. </em></p>

<hr>

<h2>Education</h2>

<b>Ph.D. in Electrical Engineering</b> (Oct 2021) <br />
Johns Hopkins University, MD, USA
<br />
<br />
<b>Masters in Electrical Engineering</b> (May 2016) <br />
Johns Hopkins University, MD, USA
<br />
<br />
<b>B.Eng Electrical Engineering / Minor in Arabic Language</b> (Dec 2013) <br />
McGill University, QC, CA

<hr>

<h2>Projects</h2>
<a href="https://github.com/m-wiesner/nnet_pytorch/tree/conda_install">nnet_pytorch: A pytorch replacement for nnet3 in Kaldi</a><br />
<a href="https://github.com/m-wiesner/Jotto">Jotto: The Code Breaking Game</a><br />
<a href="https://github.com/m-wiesner/BCUBED">B3 Clustering Metric</a><br />
<a href="https://soundcloud.com/groschatorange">Music</a>

<h2><a href="https://m-wiesner.github.io/Matthew_s_Resume-7.pdf">Résumé</a></h2>

